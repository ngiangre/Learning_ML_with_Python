{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Classification Accuracy\n",
      "\n",
      "Accuracy: 0.770 (0.048)\n",
      "\n",
      "2. Logarthmic Loss\n",
      "\n",
      "Logloss: -0.493 (0.047)\n",
      "\n",
      "3. Area under ROC curve\n",
      "\n",
      "AUC: 0.824 (0.041)\n",
      "\n",
      "4. Confusion Matrix\n",
      "\n",
      "[[141  21]\n",
      " [ 41  51]]\n",
      "\n",
      "5. Classification Report\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.87      0.82       162\n",
      "        1.0       0.71      0.55      0.62        92\n",
      "\n",
      "avg / total       0.75      0.76      0.75       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "#Classification Metrics\n",
    "#\n",
    "#Choice of metrics influences how the \n",
    "#performance of machine learning algorithms \n",
    "#is measured and compared. They influence \n",
    "#how you weight the importance of different \n",
    "#characteristics in the results and your \n",
    "#ultimate choice of which algorithm to choose.\n",
    "#\n",
    "#http://machinelearningmastery.com/metrics-evaluate-machine-learning-algorithms-python/\n",
    "########################################\n",
    "\n",
    "# 1. Classification Accuracy\n",
    "\n",
    "# Classification accuracy is the number of \n",
    "# correct predictions made as a ratio of \n",
    "# all predictions made.\n",
    "\n",
    "# This is the most common evaluation metric \n",
    "# for classification problems, it is also the \n",
    "# most misused. It is really only suitable when \n",
    "# there are an equal number of observations in \n",
    "# each class (which is rarely the case) and that \n",
    "# all predictions and prediction errors are \n",
    "# equally important, which is often not the case.\n",
    "\n",
    "# Cross Validation Classification Accuracy\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"\\n1. Classification Accuracy\\n\")\n",
    "print(\"Accuracy: %.3f (%.3f)\" % (results.mean(), results.std()))\n",
    "\n",
    "\n",
    "# 2. Logarthmic Loss\n",
    "\n",
    "# Logarithmic loss (or logloss) is a performance \n",
    "# metric for evaluating the predictions of \n",
    "# probabilities of membership to a given class.\n",
    "\n",
    "# Cross Validation Classification LogLoss\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "scoring = 'neg_log_loss'\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"\\n2. Logarthmic Loss\\n\")\n",
    "print(\"Logloss: %.3f (%.3f)\" % (results.mean(), results.std()))\n",
    "\n",
    "\n",
    "# 3. Area under ROC curve\n",
    "\n",
    "# for binary classification problems\n",
    "\n",
    "# The AUC represents a modelâ€™s ability to discriminate \n",
    "# between positive and negative classes. An area of \n",
    "# 1.0 represents a model that made all predictions \n",
    "# perfectly. An area of 0.5 represents a model as good as random.\n",
    "\n",
    "# Cross Validation Classification ROC AUC\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "scoring = 'roc_auc'\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"\\n3. Area under ROC curve\\n\")\n",
    "print(\"AUC: %.3f (%.3f)\" % (results.mean(), results.std()))\n",
    "\n",
    "\n",
    "# 4. Confusion Matrix\n",
    "\n",
    "# handy presentation of accuracy\n",
    "\n",
    "# Cross Validation Classification Confusion Matrix\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(Y_test, predicted)\n",
    "print(\"\\n4. Confusion Matrix\\n\")\n",
    "print(matrix)\n",
    "\n",
    "\n",
    "# 5. Classification Report\n",
    "\n",
    "# The classification_report() function displays \n",
    "#the precision, recall, f1-score and support for each class.\n",
    "\n",
    "# Cross Validation Classification Report\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(\"\\n5. Classification Report\\n\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
